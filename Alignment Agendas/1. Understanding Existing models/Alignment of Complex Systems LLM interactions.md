#Evals 
- _One-sentence summary_: understand LLM interactions, their limits, and work up from empirical work towards more general hypotheses about complex systems of LLMs, such as network effects in hybrid systems and scaffolded models.
- _Theory of change:_ Aggregates are sometimes easier to predict / theorise than individuals: the details average out. So experiment with LLM interactions (manipulation, conflict resolution, systemic biases etc). Direct research towards LLM interactions in future large systems (in contrast to the current singleton focus); prevent systemic bad design and inform future models.
- _Some names:_ Jan Kulveit, Tomáš Gavenčiak, Ada Böhm
- _Estimated # FTEs:_ 4
- _Some outputs in 2023_: [software](https://github.com/acsresearch/interlab) and [insights](https://acsresearch.org/posts) into LLMs
- _Critiques:_ [Yudkowsky](https://www.lesswrong.com/posts/H5iGhDhQBtoDpCBZ2/announcing-the-alignment-of-complex-systems-research-group?commentId=frEufx3c6cRmhDjbh) on the interfaces idea
- _Funded by:_ SFF
- _Trustworthy command, closure, opsec, common good, alignment mindset: ?_
- _Resources:_ ~$300,000


[[Jan Kulveit]]
[[Tomáš Gavenčiak]]